{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "from nbconvert import HTMLExporter\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time, sleep\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10('./data', train = True, download=True, transform = transform)\n",
    "test_data = datasets.CIFAR10('./data', train = False, download=True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample_model(pl.LightningModule):\n",
    "    def __init__(self, hyperparameters):\n",
    "        super().__init__()\n",
    "        \n",
    "        '''\n",
    "        model.state_dict() # 모델 weight 확인\n",
    "        model.hparams # 모델 하이퍼파라미터 확인\n",
    "\n",
    "        # 모델 학습, folder : 저장 경로\n",
    "        model.fit(train_dataloader, train_dataloader, folder) \n",
    "\n",
    "        # metric은 nn.Loss나 새로운 형태의 loss를 정의해도 됨, default는 학습 때 사용한 metric과 같음. \n",
    "\n",
    "        def accuracy (y_hat, y) : # manual metric example\n",
    "            return torch.sum(torch.max(y_hat, axis = 1)[1] == y).item()/len(y_hat)\n",
    "        \n",
    "        # 모델 테스트\n",
    "        model.test(test_dataloader, 'metric 이름', metric)\n",
    "        \n",
    "        # 저장된 ckpt 불러오기\n",
    "        model = model.load_model(ckpt_path)\n",
    "        \n",
    "        # tensorboard\n",
    "        현재 dir에서\n",
    "        tensorboard --logdir=./best_model\n",
    "        \n",
    "        # 모델 폴더 안에\n",
    "        hparams.yaml : 하이퍼파라미터 및 loss 저장\n",
    "        output_file.html : 실행 당시 ipynb 파일\n",
    "        '''\n",
    "        \n",
    "        self.get_notebook_name()\n",
    "        self.checkpoint_callback = None\n",
    "        \n",
    "        if 'validation_loss' in hyperparameters.keys() :\n",
    "            self.hparams.training_loss = hyperparameters['training_loss']\n",
    "            self.hparams.validation_loss = hyperparameters['validation_loss']\n",
    "        else : \n",
    "            self.hparams.training_loss = {}\n",
    "            self.hparams.validation_loss = {}\n",
    "            \n",
    "        if 'now' in hyperparameters.keys() :\n",
    "            self.hparams.now = hyperparameters['now']\n",
    "        else :\n",
    "            self.hparams.now = None\n",
    "\n",
    "        self.hparams.lr = hyperparameters['lr']\n",
    "        self.hparams.step_size = hyperparameters['step_size'] # epoch 단위로 계산됨.\n",
    "        self.hparams.gamma = hyperparameters['gamma']\n",
    "        self.hparams.batch_size = hyperparameters['batch_size']\n",
    "        self.hparams.max_epochs = hyperparameters['max_epochs']\n",
    "        self.hparams.gpus = hyperparameters['gpus']\n",
    "        self.hparams.auto_lr_find = hyperparameters['auto_lr_find']\n",
    "        self.hparams.save_top_k = hyperparameters['save_top_k']\n",
    "        self.hparams.num_workers = hyperparameters['num_workers']\n",
    "        self.hparams.folder = hyperparameters['folder']\n",
    "\n",
    "        ###################### model layer ######################\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3)\n",
    "        self.linear = nn.Linear(16 * 6 * 6, 10)\n",
    "\n",
    "        \n",
    "    ################# specific model structure #################\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.max_pool(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.max_pool(x))\n",
    "        x = F.relu(self.linear(x.view(x.size(0), -1)))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    ################## optimizer & scheduler ##################\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = StepLR(optimizer, step_size=self.hparams.step_size, \n",
    "                           gamma=self.hparams.gamma)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    \n",
    "    ################################ Do not change ################################\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "\n",
    "        result = pl.TrainResult(loss)\n",
    "        result.log('train_loss', loss, on_epoch=True)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def training_epoch_end(self, outputs) :\n",
    "        \n",
    "        for key, value in outputs.items() :\n",
    "            try :\n",
    "                outputs[key] = torch.mean(outputs[key])\n",
    "            except :\n",
    "                continue\n",
    "                \n",
    "        self.hparams.training_loss['epoch : %s' % self.current_epoch] = outputs[list(outputs.keys())[-1]].item()\n",
    "        \n",
    "        train_loss = self.hparams.training_loss['epoch : %s' % self.current_epoch]\n",
    "        validation_loss = self.hparams.validation_loss['epoch : %s' % self.current_epoch]\n",
    "        \n",
    "        print('epoch : %s, training loss : %.4f, validation loss : %.4f, ckpt_path = %s/%s' % \\\n",
    "              (self.current_epoch, train_loss, validation_loss, self.hparams.now,\n",
    "               ('epoch=%s_val_loss=%.4f' % (self.current_epoch, validation_loss))\n",
    "              )) \n",
    "\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) \n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('val_loss', loss)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validation_epoch_end(self, val_outputs):\n",
    "        self.hparams.validation_loss['epoch : %s' % self.current_epoch] = torch.mean(val_outputs['val_loss']).item()  \n",
    "        val_outputs['val_loss'] = torch.mean(val_outputs['val_loss'])\n",
    "        \n",
    "        return val_outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, train_data, test_data) :\n",
    "        \n",
    "        self.hparams.now = datetime.now().strftime(\"%y%m%d_%H:%M:%S\")\n",
    "        checkpoint_callback, tb_logger = self.call_logger()\n",
    "\n",
    "        self.trainer = pl.Trainer(max_epochs=self.hparams.max_epochs, gpus = self.hparams.gpus, \n",
    "                                  auto_lr_find=self.hparams.auto_lr_find, \n",
    "                             checkpoint_callback=checkpoint_callback, logger = tb_logger)\n",
    "        self.save_notebook()\n",
    "        sleep(1.0)\n",
    "\n",
    "        current_file = this_notebook\n",
    "        self.output_HTML(current_file, './%s/%s/' % (self.hparams.folder, self.hparams.now))\n",
    "        self.trainer.fit(self, train_dataloader, test_dataloader)        \n",
    "        \n",
    "        \n",
    "    def get_notebook_name(self) :\n",
    "        display(Javascript('Jupyter.notebook.kernel.execute(\\\n",
    "                           \"this_notebook = \" + \"\\'\"\\\n",
    "                           +Jupyter.notebook.notebook_name+\"\\'\");'))\n",
    "\n",
    "\n",
    "    def save_notebook(self):\n",
    "        display(\n",
    "            Javascript(\"IPython.notebook.save_notebook()\"),\n",
    "            include=['application/javascript']\n",
    "        )\n",
    "\n",
    "    def output_HTML(self, current_file, path):\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        \n",
    "        output_notebook = nbformat.read(current_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(path +'output_file.html', 'w', encoding='utf-8').write(output)\n",
    "        \n",
    "    def test(self, dataloader, metric_name, loss = None) :\n",
    "        checkpoint_callback, tb_logger = self.call_logger()\n",
    "    \n",
    "        self.trainer = pl.Trainer(max_epochs=self.hparams.max_epochs, gpus = self.hparams.gpus, \n",
    "                                  auto_lr_find=self.hparams.auto_lr_find, \n",
    "                             checkpoint_callback=checkpoint_callback, logger = tb_logger)\n",
    "        \n",
    "        if loss is not None :\n",
    "            self.test_loss = loss\n",
    "        else :\n",
    "            self.test_loss = self.loss\n",
    "            \n",
    "        self.test_metric = metric_name\n",
    "        self.trainer.test(self, dataloader)\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) \n",
    "        loss = self.test_loss(y_hat, y) * len(batch)\n",
    "        return {'loss' : loss, 'len' : len(batch)}\n",
    "        \n",
    "    \n",
    "    def test_epoch_end(self, outputs) :\n",
    "        sum_loss = 0\n",
    "        sum_len = 0\n",
    "        \n",
    "        for i in outputs :\n",
    "            sum_loss += i['loss']\n",
    "            sum_len += i['len']\n",
    "            \n",
    "        return {self.test_metric : sum_loss/sum_len}\n",
    "    \n",
    "    def call_logger(self) :\n",
    "        filepath=os.getcwd() + '/%s/%s/{epoch:d}_{val_loss:.4f}' % (self.hparams.folder, \n",
    "                                                                    self.hparams.now)\n",
    "        \n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath,\n",
    "            save_top_k=self.hparams.save_top_k,\n",
    "            monitor='val_loss',\n",
    "            mode='min')\n",
    "\n",
    "        tb_logger = pl.loggers.TensorBoardLogger(save_dir=self.hparams.folder, name = None, \n",
    "                                                 version = self.hparams.now)\n",
    "        return checkpoint_callback, tb_logger\n",
    "    \n",
    "    def load_model(self, ckpt_path) :\n",
    "        loaded_model = self.load_from_checkpoint('./%s/%s.ckpt' % (self.hparams.folder, \n",
    "                                                                   ckpt_path), \n",
    "                                         hparams_file = './%s/%s/hparams.yaml' % \\\n",
    "                                           (self.hparams.folder, ckpt_path.split('/')[0]))\n",
    "        \n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = EasyDict({'lr' : 0.007,\n",
    "                            'max_epochs' :5,\n",
    "                            'step_size' : 1,\n",
    "                            'gamma' : 0.9,\n",
    "                            'batch_size' : 256,\n",
    "                            'gpus' : [0],\n",
    "                            'num_workers' : 16,\n",
    "                            'auto_lr_find' : True,\n",
    "                            'save_top_k' : 3,\n",
    "                            'folder' : 'best_model'\n",
    "                           })\n",
    "\n",
    "\n",
    "if not os.path.isdir(hyperparameters['folder']) :\n",
    "    os.mkdir(hyperparameters['folder'])\n",
    "batch_size = hyperparameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=16) \n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False, \n",
    "                             num_workers=16 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.kernel.execute(                           \"this_notebook = \" + \"'\"                           +Jupyter.notebook.notebook_name+\"'\");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sample_model(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | loss     | CrossEntropyLoss | 0     \n",
      "1 | conv1    | Conv2d           | 896   \n",
      "2 | max_pool | MaxPool2d        | 0     \n",
      "3 | conv2    | Conv2d           | 4 K   \n",
      "4 | linear   | Linear           | 5 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa105e1208334cbea681a42c3cbc86c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, training loss : 1.9090, validation loss : 1.7563, ckpt_path = 200828_18:07:01/epoch=0_val_loss=1.7563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, training loss : 1.7187, validation loss : 1.6968, ckpt_path = 200828_18:07:01/epoch=1_val_loss=1.6968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, training loss : 1.6354, validation loss : 1.6828, ckpt_path = 200828_18:07:01/epoch=2_val_loss=1.6828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, training loss : 1.6008, validation loss : 1.6445, ckpt_path = 200828_18:07:01/epoch=3_val_loss=1.6445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4, training loss : 1.5770, validation loss : 1.5865, ckpt_path = 200828_18:07:01/epoch=4_val_loss=1.5865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5, training loss : 1.5629, validation loss : 1.5915, ckpt_path = 200828_18:07:01/epoch=5_val_loss=1.5915\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6, training loss : 1.5418, validation loss : 1.5690, ckpt_path = 200828_18:07:01/epoch=6_val_loss=1.5690\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7, training loss : 1.5254, validation loss : 1.5587, ckpt_path = 200828_18:07:01/epoch=7_val_loss=1.5587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8, training loss : 1.5198, validation loss : 1.5579, ckpt_path = 200828_18:07:01/epoch=8_val_loss=1.5579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9, training loss : 1.5083, validation loss : 1.5579, ckpt_path = 200828_18:07:01/epoch=9_val_loss=1.5579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (y_hat, y) :\n",
    "    return torch.sum(torch.max(y_hat, axis = 1)[1] == y).item()/len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b00dad473342fe893305a114a2c59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'metric 이름': 0.5047}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.test(test_dataloader, 'test accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.kernel.execute(                           \"this_notebook = \" + \"'\"                           +Jupyter.notebook.notebook_name+\"'\");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.load_model('200828_18:07:01/epoch=8_val_loss=1.5579')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b884b47fb14cc288bb0cb31fffcde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'metric 이름': 0.2309}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.test(test_dataloader, 'test accuracy', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
